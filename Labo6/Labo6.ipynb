{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTOuTJ0RFJT6",
        "outputId": "2ef7eada-3f00-475b-f6d5-42572e8b728e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('reuters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzbVHo3xFKm9",
        "outputId": "c09c97bf-dfa2-4acb-bb4d-f5e21e50fc86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training files :  7769\n",
            "testing files :  3019\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import reuters\n",
        "print('training files : ', len([fid for fid in reuters.fileids() if fid[:5] == 'train']))\n",
        "print('testing files : ', len([fid for fid in reuters.fileids() if fid[:4] == 'test']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nQX-FE9WFLsN"
      },
      "outputs": [],
      "source": [
        "# Fonction pour obtenir le texte du document en supprimant les sauts de ligne '\\n'\n",
        "def get_text(fileid):\n",
        "    return reuters.raw(fileid).replace('\\n', ' ')\n",
        "\n",
        "# Fonction qui retourne le label 1 pour 'grain' et 0 sinon\n",
        "def get_label(fileid):\n",
        "    return 1 if 'grain' in reuters.categories(fileid) else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JGHthK4qFM6n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import reuters\n",
        "\n",
        "# Récupération des différents documents en fonction du nom de fichier\n",
        "train_data = [[get_text(fileid), get_label(fileid)] for fileid in reuters.fileids() if fileid.startswith('train')]\n",
        "test_data = [[get_text(fileid), get_label(fileid)] for fileid in reuters.fileids() if fileid.startswith('test')]\n",
        "\n",
        "# Création des DataFrames pandas\n",
        "train = pd.DataFrame(train_data, columns=['text', 'label'])\n",
        "test = pd.DataFrame(test_data, columns=['text', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vStxObh-FRyW"
      },
      "outputs": [],
      "source": [
        "# Sélection de la pipeline à tester\n",
        "def set_search(experimental=False):\n",
        "    pipeline = experimental_pipeline if experimental else default_pipeline\n",
        "    parameter_grid = (parameter_grid_experimental if experimental\n",
        "                      else parameter_grid_default)\n",
        "\n",
        "    search = GridSearchCV(\n",
        "        pipeline,\n",
        "        parameter_grid,\n",
        "        scoring='f1_micro',\n",
        "        cv=3,\n",
        "        n_jobs=-1,\n",
        "        verbose=2\n",
        "    )\n",
        "    print(\"Testing pipeline:\", pipeline)\n",
        "    return search, parameter_grid\n",
        "\n",
        "# Entraînement de la pipeline puis calcul des performances sur les données de tesst\n",
        "def test_data(search):\n",
        "    print(\"Evaluating pipeline...\")\n",
        "    start = time()\n",
        "    search.fit(train['text'], train['label'])\n",
        "    end = time()\n",
        "    print(f\"Training time: {end - start:.3f}s\")\n",
        "\n",
        "    test_accuracy = search.score(test['text'], test['label'])\n",
        "\n",
        "    print(f\"Accuracy on test set: {test_accuracy:.3f}\")\n",
        "\n",
        "# Affichage des meilleurs hyperparamètres trouvés\n",
        "def display_params(search, parameter_grid):\n",
        "    print(\"Best parameters combination found:\")\n",
        "    best_parameters = search.best_estimator_.get_params()\n",
        "    for param_name in sorted(parameter_grid.keys()):\n",
        "        print(f\"{param_name}: {best_parameters[param_name]}\")\n",
        "\n",
        "# Création de la pipeline, entraînement, test et affichage des paramètres trouvés\n",
        "def search_best_parameters(experimental=False):\n",
        "    [search, parameter_grid] = set_search(experimental)\n",
        "\n",
        "    test_data(search)\n",
        "    display_params(search, parameter_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_HdzVl8E9Eh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dcc58bb-382d-45f2-cca7-616a68264f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing pipeline: Pipeline(steps=[('vect', TfidfVectorizer()), ('clf', ComplementNB())])\n",
            "Evaluating pipeline...\n",
            "Fitting 3 folds for each of 1040 candidates, totalling 3120 fits\n"
          ]
        }
      ],
      "source": [
        "from time import time\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "default_pipeline = Pipeline(\n",
        "    [\n",
        "        (\"vect\", TfidfVectorizer()),\n",
        "        (\"clf\", ComplementNB()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "experimental_pipeline = Pipeline(\n",
        "    [\n",
        "        (\"vect\", CountVectorizer()),\n",
        "        (\"clf\", SGDClassifier(loss='hinge'))\n",
        "    ]\n",
        ")\n",
        "\n",
        "parameter_grid_default = {\n",
        "    \"vect__max_df\": (0.2, 0.4, 0.6, 0.8, 1.0),\n",
        "    \"vect__min_df\": (1, 3, 5, 10),\n",
        "    \"vect__ngram_range\": ((1, 1), (1, 2)),\n",
        "    \"vect__norm\": (\"l1\", \"l2\"),  # normalization options for TFIDF\n",
        "    \"clf__alpha\": np.logspace(-6, 6, 13),\n",
        "}\n",
        "\n",
        "parameter_grid_experimental = {\n",
        "    \"vect__max_df\": (0.2, 0.4, 0.6, 0.8, 1.0),\n",
        "    \"vect__min_df\": (1, 3, 5, 10),\n",
        "    \"vect__ngram_range\": ((1, 1), (1, 2)),\n",
        "    \"clf__alpha\": np.logspace(-6, 6, 13),\n",
        "}\n",
        "\n",
        "for experimental in [False, True]:\n",
        "    search_best_parameters(experimental)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAjqVo5fFVj2"
      },
      "outputs": [],
      "source": [
        "#TODO :\n",
        "# 1) Présenter le score f1 sur l'ensemble de test avec la meilleure configuration trouvée\n",
        "# 2) Présenter la loss et l'accuracy\n",
        "# 3) Pourquoi pas ajouter une matrice de confusion sur les résultats de la classe \"grain\" (l'assistant aimerait bien à mon avis)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}