{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "inside-craps",
   "metadata": {},
   "source": [
    "# Demo of feature selection methods in Python\n",
    "\n",
    "Three methods for feature selection are exemplified in this notebook.\n",
    "* SelectKBest (filter)\n",
    "* RFE with logistic regression (wrapper)\n",
    "* Ridge (embedded)\n",
    "\n",
    "The code is inspired by: https://www.datacamp.com/community/tutorials/feature-selection-python and improves the notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharing-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intense-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data: from URL or local file\n",
    "# uri = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "uri = \"pima-indians-diabetes-no-header.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = pd.read_csv(uri, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "academic-reply",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1\n",
       "5     5   116    74     0     0  25.6  0.201   30      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "separated-introduction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-broad",
   "metadata": {},
   "source": [
    "There are 8 different features, and the outcomes (last column) are labeled 1 and 0:\n",
    "* 1 denotes that the observed person has diabetes\n",
    "* 0 denotes that the observed person *does not* have diabetes \n",
    "\n",
    "Note. The original dataset is known to have missing values. Specifically, there are missing observations for some columns that are marked as a zero value.  For this demo, we use a preprocessed version of the dataset.  It can be obtained from the URL above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "august-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the DataFrame object to a NumPy array to achieve faster computation\n",
    "pima_array = df.values\n",
    "# separate features from labels\n",
    "X = pima_array[:,0:8]\n",
    "Y = pima_array[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-result",
   "metadata": {},
   "source": [
    "## 1. Select best features with Chi-squared\n",
    "\n",
    "The Chi-Squared statistical test for *non-negative* features will select 4 of the best features from the dataset. The Chi-Squared test belongs the class of filter methods.\n",
    "\n",
    "Scikit-learn provides the `SelectKBest` class that can be used with a suite of different statistical tests (in our case, Chi-Squared) to select a specific number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adapted-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excited-visitor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=4, score_func=<function chi2 at 0x00000154D650DCA0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature selection -- without transformation\n",
    "sel = SelectKBest(score_func = chi2, k = 4)\n",
    "sel.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "light-clearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 111.52  1411.887   17.605   53.108 2175.565  127.669    5.393  181.304]\n",
      "[False  True False False  True  True False  True]\n",
      "[1 4 5 7]\n"
     ]
    }
   ],
   "source": [
    "# Summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "print(sel.scores_)\n",
    "print(sel.get_support())\n",
    "print(sel.get_support(indices=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-thriller",
   "metadata": {},
   "source": [
    "We can see the scores for each attribute.  The four attributes chosen are those with the highest scores (plas, test, mass, and age).  And with `get_support()` we get to see which ones were selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cheap-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = sel.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "established-willow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148.    0.   33.6  50. ]\n",
      " [ 85.    0.   26.6  31. ]\n",
      " [183.    0.   23.3  32. ]\n",
      " [ 89.   94.   28.1  21. ]]\n"
     ]
    }
   ],
   "source": [
    "# Display the first 4 lines with the 4 selected features\n",
    "print(X_new[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "introductory-johns",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 111.52  1411.887   17.605   53.108 2175.565  127.669    5.393  181.304]\n",
      "[1 4 5 7]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plas</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   plas  test  mass  age\n",
       "0   148     0  33.6   50\n",
       "1    85     0  26.6   31\n",
       "2   183     0  23.3   32\n",
       "3    89    94  28.1   21"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to do it on the df, to see the column names\n",
    "# https://stackoverflow.com/questions/39839112/the-easiest-way-for-getting-feature-names-after-running-selectkbest-in-scikit-le\n",
    "sel.fit(df[names[0:8]], df[names[8:9]])\n",
    "print(sel.scores_)\n",
    "cols = sel.get_support(indices=True)\n",
    "print(cols)\n",
    "df_features_new = df[names[0:8]].iloc[:,cols]\n",
    "df_features_new.head(4) # we get the df and names, but haven't added the class (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-munich",
   "metadata": {},
   "source": [
    "## 2. Select best features with Recursive Feature Elimination\n",
    "\n",
    "RFE is a type of wrapper feature selection method. It works by recursively removing attributes and building a model on those attributes that remain.  It uses the outputs of the model  to identify which attributes contribute the most to predicting the target attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "annual-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# We will use RFE with the Logistic Regression classifier to select the top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "behavioral-special",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 3\n",
      "Selected features:  [ True False False False False  True  True False]\n",
      "Feature ranking:    [1 2 4 6 5 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "estimator = LogisticRegression(solver='lbfgs', max_iter=200) # increased 'max_iter' to avoid an error message\n",
    "sel2 = RFE(estimator, n_features_to_select=3)\n",
    "sel2.fit(X, Y)\n",
    "print(\"Number of features:\", sel2.n_features_)\n",
    "print(\"Selected features: \", sel2.support_)\n",
    "print(\"Feature ranking:   \", sel2.ranking_)\n",
    "# Reminder: names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-netherlands",
   "metadata": {},
   "source": [
    "RFE chose the following top 3 features: preg, mass, and pedi.  These are marked True in the support array and marked with a choice “1” in the ranking array. This, in turn, indicates the strength of the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-guarantee",
   "metadata": {},
   "source": [
    "## 3. Select best features with Ridge regression\n",
    "\n",
    "Ridge regression is basically a regularization technique with L2 norm, and can be used as an embedded feature selection technique as well.\n",
    "See [this article](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/#three) for an excellent explanation on Ridge regression. You can also check scikit-learn's official documentation on Ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "impressed-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# Linear least squares with l2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "phantom-watch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X,Y)\n",
    "# Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, normalize=False, random_state=None, solver='auto', tol=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-consequence",
   "metadata": {},
   "source": [
    "In order to better understand the results of Ridge regression, we use a helper function that prints the results so that we can interpret them easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "interstate-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_coefs(coefs, names = None, sort = False):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name) for coef, name in lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "renewable-details",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge model: 0.021 * X0 + 0.006 * X1 + -0.002 * X2 + 0.0 * X3 + -0.0 * X4 + 0.013 * X5 + 0.145 * X6 + 0.003 * X7\n"
     ]
    }
   ],
   "source": [
    "# pass Ridge model's coefficient terms to this function\n",
    "\n",
    "print (\"Ridge model:\", pretty_print_coefs(model.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-sunglasses",
   "metadata": {},
   "source": [
    "This shows all the coefficients appended with the features. They can help to choose the most important features by taking the highest coefficients.  Here, features 6 (especially), then 0 and then 5 are ranked high.  With the previous methods, we had 1-4-5-7, so it's not the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "unlikely-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "conscious-italy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=Ridge(), threshold='0.5*mean')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel3 = SelectFromModel(estimator=Ridge(), threshold=\"0.5*mean\")\n",
    "sel3.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "established-milton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.021  0.006 -0.002  0.    -0.     0.013  0.145  0.003]\n",
      "0.01190245478065201\n",
      "[ True False False False False  True  True False]\n",
      "[0 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(sel3.estimator_.coef_)\n",
    "print(sel3.threshold_)\n",
    "print(sel3.get_support())\n",
    "print(sel3.get_support(indices=True))\n",
    "# not available : sel3.n_features_, sel3.support_, sel3.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-portuguese",
   "metadata": {},
   "source": [
    "### Let's try with Lasso too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "electoral-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "small-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel4 = SelectFromModel(estimator=Lasso(alpha=1.0), threshold=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "imposed-spyware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=Lasso(), threshold='mean')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel4.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "certain-bloom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.     0.006  0.     0.    -0.     0.     0.     0.   ]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(sel4.estimator_.coef_)\n",
    "print(sel4.get_support(indices=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-agenda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
